# DreamerV4 Configuration for MineRL Full Dataset - Phase 1 Training
# Based on: "Training Agents Inside of Scalable World Models"
# Uses full extracted MineRL dataset with time-based checkpointing

# Experiment settings
experiment:
  name: "dreamerv4_minerl_full"
  seed: 42
  device: "cuda"
  log_dir: "logs/full"
  checkpoint_dir: "checkpoints/full"

# Data settings
data:
  path: "data/mineRL_extracted"  # Full extracted MineRL dataset
  sequence_length: 16
  image_height: 64
  image_width: 64
  in_channels: 3
  batch_size: 8  # 2x subset config
  num_workers: 4
  frame_skip: 1
  resize_to: null
  max_episodes: null  # Use all episodes

# Tokenizer settings (shared transformer architecture)
tokenizer:
  patch_size: 8
  embed_dim: 256
  latent_dim: 32
  num_latent_tokens: 16
  depth: 6
  num_heads: 8
  dropout: 0.0
  num_registers: 4
  mask_ratio: 0.75

# Dynamics model settings
dynamics:
  max_shortcut_steps: 6
  num_discrete_actions: 144
  action_space_type: "categorical"
  num_registers: 4

# Agent heads settings
heads:
  hidden_dim: 256
  num_layers: 2
  num_bins: 255
  num_actions: 144

# Training settings
training:
  # Phase 1: World Model Pretraining
  phase1:
    epochs: 100
    max_steps: null  # Train full epochs
    learning_rate: 3.0e-4
    weight_decay: 0.01
    warmup_steps: 1000
    max_grad_norm: 1.0
    lpips_weight: 0.2
    use_lpips: true
    save_every: 1  # Save at end of every epoch (mid-epoch checkpoints are automatic)

  # Phase 2: Agent Finetuning
  phase2:
    epochs: 50
    learning_rate: 1.0e-4
    weight_decay: 0.01
    warmup_steps: 500
    max_grad_norm: 1.0
    reward_weight: 1.0
    freeze_transformer: true
    save_every: 5
    use_focal_loss: true
    focal_gamma: 2.0
    focal_alpha: 0.25
    use_mtp: true
    mtp_length: 8

  # Phase 3: Imagination Training with PMPO
  phase3:
    epochs: 100
    batch_size: 16
    imagination_horizon: 15
    num_denoising_steps: 4
    discount: 0.997
    lambda: 0.95
    pmpo_alpha: 0.5
    pmpo_beta_kl: 0.3
    entropy_coef: 0.003
    advantage_bins: 16
    use_percentile_binning: true
    percentile_threshold: 10.0
    policy_lr: 3.0e-5
    value_lr: 1.0e-4
    value_loss_scale: 0.5
    grad_clip: 1.0
    save_every: 10
    num_workers: 4

# Optimizer settings
optimizer:
  type: "adamw"
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Scheduler settings
scheduler:
  type: "cosine"
  min_lr: 1.0e-6

# Logging settings
logging:
  log_every: 100
  eval_every: 1000
  use_wandb: false
  wandb_project: "dreamerv4"
